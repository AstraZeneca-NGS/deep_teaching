{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to code a simple neural network from scratch. We will create a simple network with the following architecture to solve the XOR problem. \n",
    "\n",
    "<img height=\"365\" src=\"https://lh5.googleusercontent.com/Yinkr_2dkb08Mz_wzG-tPzqNGeQ3KnW4fuE7IwGzUjRV1a1-NjzuPS6s69rq-xtZYT26BuyzYgKO6ZRTetYqwAyhqK6W8BeePtOx33W-XgHA0BfkU8TzkcG53gmsHYLS2PT0Sbmv\" width=\"557\">\n",
    "\n",
    "We will\n",
    "* learn how to initialize neuron weights\n",
    "* learn how to 'forward propagate' data through our network\n",
    "* learn how to 'back propagate' loss information back through our network\n",
    "* and use this information to update our network neuron weights\n",
    "\n",
    "<br><br><br>\n",
    "Python / notebook cheatsheet\n",
    "* `Shift+Enter` to execute a given cell and move to / make a new next cell\n",
    "* `#` is for single line comments\n",
    "* each cell in this notebook can be either of type `code` (the cell below) or type `markdown` (this cell)\n",
    "* tabs (indents) are required for any flow control (`for`, `if..else`, `while` etc)\n",
    "* `=` is for assignment\n",
    "* `()` is to call a function or method\n",
    "* `[]` is for indexing into a variable\n",
    "* a quick way to post-hoc to put parenthesis or brackets around something, just select that something and type `(` or `[`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_WEIGHT_FACTOR = 0.5\n",
    "\n",
    "# Training data\n",
    "XOR_INPUTS = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "XOR_OUTPUTS = np.array([0.1, 0.9, 0.9, 0.1])\n",
    "\n",
    "neuron_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the training data\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "plt.scatter(XOR_INPUTS[:,0],XOR_INPUTS[:,1],c=np.round(XOR_OUTPUTS),cmap=cm_bright)\n",
    "plt.xlim([-2,2])\n",
    "plt.ylim([-2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    '''\n",
    "    Neuron for backpropagation\n",
    "    IMPORTANT: This is built for educational pourposes, efficiency is not a concern.\n",
    "    '''\n",
    "    def __init__(self, input_neurons=list()):\n",
    "        ''' Initialzie parameters '''\n",
    "        global neuron_id\n",
    "        self.id = neuron_id\n",
    "        neuron_id += 1\n",
    "        self.fan_in = len(input_neurons)\n",
    "        self.out = 0.0\n",
    "        self.input_neurons = input_neurons\n",
    "        self.reset_delta_w()\n",
    "        self.delta = 0\n",
    "        self.delta_sum = 0\n",
    "        self.w = # TODO: Initialize weights\n",
    "\n",
    "    def backprop(self):\n",
    "        ''' Perform a back-propagation '''\n",
    "        self.delta = self.delta_sum * self.phi_prime()\n",
    "        for i, n in enumerate(self.input_neurons):\n",
    "            # TODO: Back-propagate deltas\n",
    "            self.delta_w[i] += n.out * self.delta\n",
    "\n",
    "    def calc(self):\n",
    "        ''' Calculate neuron's output '''\n",
    "        self.delta = 0\n",
    "        self.delta_sum = 0\n",
    "        ins = np.array([n.out for n in self.input_neurons])\n",
    "        # TODO: Calculate neuron's output\n",
    "\n",
    "    def phi(self, h):\n",
    "        ''' Neuron's transfer function '''\n",
    "        return 1.0 / (1.0 + math.exp(-h))\n",
    "\n",
    "    def phi_prime(self):\n",
    "        ''' Neuron's transfer function derivate '''\n",
    "        return # TODO: Calculate transfer's function derivate\n",
    "\n",
    "    def reset_delta_w(self):\n",
    "        self.delta_w = np.zeros((self.fan_in)) # Weight update\n",
    "\n",
    "    def update_w(self, eta):\n",
    "        ''' Update weights '''\n",
    "        # TODO: Update weights\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"id: {self.id}, output: {self.out}, weights: {self.w}, delta: {self.delta}, delta_sum: {self.delta_sum}, delta_w: {self.delta_w}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    ''' A neural network to solve the XOR problem '''\n",
    "    def __init__(self, data_in, data_out):\n",
    "        ''' Create a fully connected network to solve XOR problem, return layers of neurons '''\n",
    "        self.data_in = data_in\n",
    "        self.data_out = data_out\n",
    "        # Create 'bias'\n",
    "        bias = Neuron()\n",
    "        bias.out = 1.0\n",
    "        # Create 'placeholders' for inputs\n",
    "        in1 = Neuron()\n",
    "        in2 = Neuron()\n",
    "        # Create neurons and connect them\n",
    "        n1 = Neuron([bias, in1, in2])\n",
    "        n2 = Neuron([bias, in1, in2])\n",
    "        self.n_out = Neuron([bias, n1, n2])\n",
    "        # Create layers\n",
    "        self.layers = [[in1, in2], [n1, n2], [self.n_out]]\n",
    "        self.neurons = [n for l in self.layers[1:] for n in l]\n",
    "\n",
    "    def backprop(self, num_in):\n",
    "        ''' Back-propagate weights '''\n",
    "        # Calculate output delta\n",
    "        diff_loss = (self.data_out[num_in] - self.n_out.out)\n",
    "        self.n_out.delta_sum = -diff_loss\n",
    "        # Backpropagation\n",
    "        for n in reversed(self.neurons):\n",
    "            n.backprop()\n",
    "        return diff_loss * diff_loss\n",
    "\n",
    "    def calc(self):\n",
    "        ''' Calculate outputs for all neurons (forward propagation) '''\n",
    "        for n in self.neurons:\n",
    "            n.calc()\n",
    "\n",
    "    def evaluate(self):\n",
    "        ''' Evaluate network for each input '''\n",
    "        l0 = self.layers[0]\n",
    "        num_samples = self.data_in.shape[0]\n",
    "        for i in range(num_samples):\n",
    "            self.set_inputs(i)\n",
    "            self.calc()\n",
    "            print(f\"{l0[0].out}\\t{l0[1].out}\\t=>\\t{self.n_out.out}\")\n",
    "\n",
    "    def set_inputs(self, num_in):\n",
    "        ''' Set netwok inputs with sample number 'num_in' '''\n",
    "        for j, n_in in enumerate(self.layers[0]):\n",
    "            n_in.out = self.data_in[num_in, j]\n",
    "\n",
    "    def train(self, eta):\n",
    "        ''' Train a neural network (one iteration) '''\n",
    "        sum_loss = 0.0\n",
    "        num_samples = self.data_in.shape[0]\n",
    "        n_out = self.layers[2][0]\n",
    "        for n in self.neurons:\n",
    "            n.reset_delta_w()\n",
    "        # For each input sample...\n",
    "        for i in range(num_samples):\n",
    "            self.set_inputs(i)\n",
    "            self.calc()\n",
    "            sum_loss += self.backprop(i)\n",
    "        # Update weights\n",
    "        for n in self.neurons:\n",
    "            n.update_w(eta)\n",
    "        # Return loss\n",
    "        loss = sum_loss / (2.0 * num_samples)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a network\n",
    "net = Network(XOR_INPUTS, XOR_OUTPUTS)\n",
    "\n",
    "# Train\n",
    "eta = 1\n",
    "nIter = 2000\n",
    "losses = np.zeros((nIter,))\n",
    "for i in range(nIter):\n",
    "    losses[i] = net.train(eta)\n",
    "    print(f\"Iteration: {i}\\tloss: {losses[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loss as a function of training iteration\n",
    "plt.plot(range(nIter),losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('training iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate our result after training\n",
    "# we should get something similar to XOR_OUTPUTS, i.e. [0.1, 0.9, 0.9, 0.1]\n",
    "net.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
