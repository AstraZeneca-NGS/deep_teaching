{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical convolutional neural network architecture\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*NQQiyYqJJj4PSYAeWvxutg.png\"></img>\n",
    "[image source](https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050)\n",
    "\n",
    "In this notebook we'll review basic considerations for building any neural network, build a simple convolutional neural network, visualize its weights, and compare the learned 'representation' with that of a tradition non-convolutional neural network, aka a fully connected (FC) network / multilayer perceptron (MLP)\n",
    "\n",
    "Our models might need a bit more computational power this week, so be sure to change your Google colab runtime type by clicking `Runtime`, `Change runtime type`, and then selecting `GPU`. We'll see if Google let's us all get free GPUs!\n",
    "\n",
    "<br><br><br>\n",
    "Python / notebook cheatsheet\n",
    "* `Shift+Enter` to execute a given cell and move to / make a new next cell\n",
    "* `#` is for single line comments\n",
    "* each cell in this notebook can be either of type `code` (the cell below) or type `markdown` (this cell)\n",
    "* tabs (indents) are required for any flow control (`for`, `if..else`, `while` etc)\n",
    "* `=` is for assignment\n",
    "* `()` is to call a function or method\n",
    "* `[]` is for indexing into a variable\n",
    "* a quick way to post-hoc to put parenthesis or brackets around something, just select that something and type `(` or `[`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras-specific modules we need\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Conv2D, Flatten, MaxPooling2D, Conv3D, Reshape, MaxPooling3D\n",
    "from keras.datasets import mnist, fashion_mnist, cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import RandomUniform, Zeros, Ones, glorot_uniform\n",
    "from keras.regularizers import l1,l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more packages / functions that we'll need\n",
    "from IPython.core.pylabtools import figsize\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load in our sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in keras datasets: https://keras.io/datasets/\n",
    "# load the data\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "#(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# one-hot encode labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# NOTE: we no longer need to linearize the data as we had with a non-convolutional network!\n",
    "# add a dummy 4th dim for channel\n",
    "if len(x_train.shape)<4: \n",
    "    x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],x_train.shape[2],1))\n",
    "    x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],x_test.shape[2],1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data dimensions: n samples, by n pix, by n pix, by n channels\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize sample images from input dataset\n",
    "figsize(5,5)\n",
    "for a in range(0,36):\n",
    "    plt.subplot(6,6,a+1)\n",
    "    plt.imshow(np.squeeze(x_train[a,:,:,:]),cmap='gray')\n",
    "    plt.axis('off')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale and normalize\n",
    "x_train = (x_train/255.-0.5)*2\n",
    "x_test = (x_test/255.-0.5)*2\n",
    "\n",
    "# get subsets of the data for faster model training -- for example purposes only\n",
    "x_train_subset = x_train[:6000,:,:,:]\n",
    "y_train_subset = y_train[:6000]\n",
    "x_test_subset = x_test[:1000,:,:,:]\n",
    "y_test_subset = y_test[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define our convolutional network. We will explicitly define parameters as much as we can, but do note that most of these are just the defaults. E.g. see the [keras documentation](https://keras.io/layers/about-keras-layers/)\n",
    "\n",
    "Let's make a convolutional neural network with the following\n",
    "* Two convolutional layers with `5x5` filters followed by maxpooling for each\n",
    "* One fully connected layer\n",
    "* One output classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNN(): # a function we can call to build our model\n",
    "    myCNN = Sequential() # instantiate a model\n",
    "    ## add your layers here\n",
    "\n",
    "    ## end add your layers\n",
    "    myCNN.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'],optimizer='SGD')\n",
    "    return myCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes from last month's exercise on data processing and model-building steps\n",
    "* load data\n",
    "    * vectorize data\n",
    "    * rescale data: not entirely necessary; but do need conversion to `float` from `int`\n",
    "    * one-hot encode the data labels\n",
    "* build the model\n",
    "    * add a layer with n units: you choose!\n",
    "    * initialize weights: can't do 0 weights! can't do the same weights!\n",
    "    * specify activation function: some work better than others, given gradient descent\n",
    "    * (not shown: add regularization via dropout `Dropout(..)` or L1/L2, `kernel_regularizer=l1(0.001)`)\n",
    "    * repeat for next layers\n",
    "    * add a final layer of 10 units to get predictions\n",
    "* compile the model\n",
    "    * specify loss function: https://keras.io/losses/\n",
    "    * specify how to apply the loss function: learning rates, learning rate decay, momentum\n",
    "    * specify evaluation metric(s): model doesn't care about these metrics!\n",
    "* implementation notes\n",
    "    * every time you run `fit()`, model will continue from where it left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myCNN = makeCNN() # make our model\n",
    "myCNN.summary() # show model summary\n",
    "\n",
    "# callback functions to store weights from our convolutional layers after each epoch\n",
    "layer1weights = [] # empty list to hold our weights\n",
    "layer2weights = []\n",
    "get_weights1 = LambdaCallback(on_epoch_end=lambda epoch,logs: layer1weights.append(myCNN.layers[0].get_weights())) \n",
    "get_weights2 = LambdaCallback(on_epoch_end=lambda epoch,logs: layer2weights.append(myCNN.layers[2].get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of parameters for the second convolutional layer is not `5*5*2+2`, rather it's `5*5*32*2+2` because you have a 32-channel 'image' from the previous layer for which we need to learn a kernel for each channel (you could also think of this as having `(5,5,32)` as our effective filter size). [See also visualization here](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now train the model: note you'll need to run the cell above if you don't want to start from where you left off\n",
    "history = myCNN.fit(x=x_train_subset,y=y_train_subset,batch_size=64,epochs=30,validation_data=(x_test_subset,y_test_subset), callbacks=[get_weights1,get_weights2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our model's performance over time with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12,4)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss per epoch')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('categorical crossentropy loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.title('10-way classification accuracy per epoch')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('categorical accuracy')\n",
    "''''''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the learned weights. Per the lecture, we expect the network has learned a set of edge-detecting filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's see what weights there are\n",
    "modelweights = myCNN.get_weights()\n",
    "modellayers = ['Conv1','C1bias','Conv2','C2bias','FC1','FC1bias']\n",
    "for layer,item in zip(modellayers,modelweights):\n",
    "    print(str(layer) + ' weights shape: \\t' + str(item.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out first convolutional layer's learned filters\n",
    "modelweights = myCNN.get_weights() # get model weights\n",
    "conv1weights = modelweights[0] # get first conv layer's weights\n",
    "\n",
    "figsize(8, 4)\n",
    "Counter = 0\n",
    "plt.suptitle('1st convolutional layer filters')\n",
    "for a in range(0,4):\n",
    "    for b in range(0,8):\n",
    "        plt.subplot(4,8,Counter+1)\n",
    "        plt.imshow(np.squeeze(conv1weights[:,:,0,Counter]))\n",
    "        plt.axis('off')\n",
    "        Counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize how the filters change after each training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8, 4)\n",
    "fig, ax = plt.subplots(4,8)\n",
    "fig.suptitle('1st convolutional layer filters by epoch')\n",
    "weightplots = []\n",
    "for c in range(0,len(layer1weights)):\n",
    "    currweights = layer1weights[c][0] # get weights from current epoch\n",
    "    Counter = 0\n",
    "    weightsubplots = []\n",
    "    for a in range(0,4):\n",
    "        for b in range(0,8):\n",
    "            ax[a,b].axis('off')\n",
    "            img = ax[a,b].imshow(np.squeeze(currweights[:,:,0,Counter]))\n",
    "            Counter += 1\n",
    "            weightsubplots.append(img) # append to list of subplots\n",
    "    weightplots.append(weightsubplots) # append to list of figure frames\n",
    "\n",
    "anim = ArtistAnimation(fig, weightplots, interval=200) # animate with prerendered plots in `weightplots`\n",
    "plt.close() # close the actual plotted figure\n",
    "HTML(anim.to_jshtml()) # ...and instead display a jshtml animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do learned filters look like for the 2nd convolutional layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some random filters from the second convolutional layer\n",
    "modelweights = myCNN.get_weights() # get model weights\n",
    "conv2weights = modelweights[2] # get second conv layer's weights\n",
    "conv2weights = np.reshape(conv2weights,(conv2weights.shape[0],conv2weights.shape[1],conv2weights.shape[2]*conv2weights.shape[3])) # reshape to put all weights into a single dimension\n",
    "\n",
    "figsize(8, 8)\n",
    "Counter = 0\n",
    "shuffled_indices = np.arange(conv2weights.shape[2]) # all indices\n",
    "np.random.shuffle(shuffled_indices) # ..shuffled\n",
    "plt.suptitle('Random 2nd convolutional layer filters')\n",
    "for a in range(0,8):\n",
    "    for b in range(0,8):\n",
    "        plt.subplot(8,8,Counter+1)\n",
    "        plt.imshow(np.squeeze(conv2weights[:,:,shuffled_indices[Counter]]))\n",
    "        plt.axis('off')\n",
    "        Counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that's strange! It just looks like noise? Why is this the case? (go back and examine our network, modify it, and re-run the code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After re-running the code with new parameters, let's now see how the 2nd convolutional layer weights evolve with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8, 8)\n",
    "fig, ax = plt.subplots(8,8)\n",
    "fig.suptitle('2nd convolutional layer filters by epoch (first 64)')\n",
    "weightplots = []\n",
    "for c in range(0,len(layer2weights)):\n",
    "    currweights = layer2weights[c][0] # get weights from current epoch\n",
    "    currweights = np.reshape(currweights,(5,5,1,64))\n",
    "    Counter = 0\n",
    "    weightsubplots = []\n",
    "    for a in range(0,8):\n",
    "        for b in range(0,8):\n",
    "            ax[a,b].axis('off')\n",
    "            img = ax[a,b].imshow(np.squeeze(currweights[:,:,0,Counter]))\n",
    "            Counter += 1\n",
    "            weightsubplots.append(img) # append to list of subplots\n",
    "    weightplots.append(weightsubplots) # append to list of figure frames\n",
    "\n",
    "anim = ArtistAnimation(fig, weightplots, interval=200) # animate with prerendered plots in `weightplots`\n",
    "plt.close() # close the actual plotted figure\n",
    "HTML(anim.to_jshtml()) # ...and instead display a jshtml animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the network is 'forced' to learn higher order edge features (keep in mind that we're still doing a bit of qualitative hand-waving here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to visualizing the learned filters, we can also visualize how a given input image is transformed at different stages of the network, much like we did in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the keras functional api (as opposed to Sequential model that we used before)\n",
    "# make a new model that outputs at a layer of named choice\n",
    "layer_name = 'Conv1'\n",
    "\n",
    "# note how we reuse our previous model, and thus don't need to train this new model\n",
    "middle_model = Model(inputs=myCNN.input,outputs=myCNN.get_layer(layer_name).output)\n",
    "\n",
    "# get a prediction from the new model\n",
    "layeroutput = middle_model.predict(x_test[:2,:,:,:]) \n",
    "print(layeroutput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's see the example we pushed through the network\n",
    "plt.imshow(np.squeeze(x_test[0,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sample transformed 'images' from the layer\n",
    "figsize(8,4)\n",
    "plt.suptitle('Data representation at layer: ' + layer_name)\n",
    "for a in range(32):\n",
    "    plt.subplot(4,8,a+1)\n",
    "    plt.imshow(np.squeeze(layeroutput[0,:,:,a]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as a point of comparison, here's (a slightly modified version of) the simple MLP we made during last month's coding exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a linearize version of the data\n",
    "x_train_subset_lin = np.reshape(x_train_subset,(x_train_subset.shape[0],x_train_subset.shape[1]*x_train_subset.shape[2]*x_train_subset.shape[3]))\n",
    "x_test_subset_lin = np.reshape(x_test_subset,(x_test_subset.shape[0],x_test_subset.shape[1]*x_test_subset.shape[2]*x_test_subset.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNN(): # a function we can call to build our model\n",
    "    myNN = Sequential() # instantiate a model\n",
    "    myNN.add(Dense(64,activation='relu',input_shape=(x_train_subset_lin.shape[1],)))\n",
    "    myNN.add(Dense(32,activation='relu'))\n",
    "    myNN.add(Dense(10,activation='softmax'))\n",
    "    myNN.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'],optimizer='Adam')\n",
    "    return myNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make our model\n",
    "myNN = makeNN() \n",
    "\n",
    "# train our model\n",
    "myNN.fit(x=x_train_subset_lin,y=y_train_subset,batch_size=64,epochs=10,validation_data=(x_test_subset_lin,y_test_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much as we did with the convolutional neural network, we can visualize the learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out first layer's learned weights\n",
    "modelweights = myNN.get_weights() # get model weights\n",
    "layerweights = modelweights[0] # get first layer's weights\n",
    "\n",
    "figsize(8, 8)\n",
    "Counter = 0\n",
    "plt.suptitle('1st layer filters')\n",
    "for a in range(0,8):\n",
    "    for b in range(0,8):\n",
    "        plt.subplot(8,8,Counter+1)\n",
    "        plt.imshow(np.reshape(layerweights[:,Counter],(x_train.shape[1],x_train.shape[2])))\n",
    "        plt.axis('off')\n",
    "        Counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out second layer's learned weights\n",
    "modelweights = myNN.get_weights() # get model weights\n",
    "layerweights = modelweights[2] # get second layer's weights\n",
    "\n",
    "figsize(8, 4)\n",
    "Counter = 0\n",
    "plt.suptitle('2nd layer filters')\n",
    "for a in range(0,4):\n",
    "    for b in range(0,8):\n",
    "        plt.subplot(4,8,Counter+1)\n",
    "        plt.imshow(np.reshape(layerweights[:,Counter],(int(layerweights.shape[0]**0.5),int(layerweights.shape[0]**0.5))))\n",
    "        plt.axis('off')\n",
    "        Counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take-home messages\n",
    "* Simple 'feed-foward' networks such as MLP's and convolutional neural networks are easy to code up\n",
    "    * we'll find that these days, even more complex architectures such as recurrent neural networks are almost as easy to code up with modern tools\n",
    "* There are simple methods to visualize what the network has learned\n",
    "    * via observing weights or intermediate outputs, as done here\n",
    "    * or via other methods: [deconvolutional networks](https://arxiv.org/abs/1311.2901), [compute input that maximally activates a layer](https://arxiv.org/abs/1312.6034), [saliency maps](https://arxiv.org/abs/1810.03292), etc.\n",
    "* Neural networks, and machine learning models in general, will learn whatever weights they need in order to solve the problem (i.e. minimize the loss function). And so there are no guarantees as to the structure of what they learn without imposing constraints\n",
    "    * but then by imposing significant constraints (via loss functions, hyperparameters, architectures, etc), you limit how the network can learn and we get back to the 'hand-crafting' approaches of yore\n",
    "    * nonetheless, this comes back to the concept from our lecture, i.e. choosing the 'right' prior\n",
    "    * a convolutional neural network can be thought of as a network with constraints or priors built-in, and which (favorably) constrain how the network can learn\n",
    "* There are canonical datasets that can be easily dropped into your given model for rapid testing, prototyping, and benchmarking, e.g. https://keras.io/datasets/\n",
    "    * uncomment the lines for the other two datasets at the top and see how your model performs!\n",
    "* Further still, there are pre-trained networks that can be easily loaded and used for, e.g. transfer learning: https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheatsheet below to complete the coding exercise\n",
    "```\n",
    "    # change filters of 2nd conv layer to 2, and run for 50, not 30 epochs; or run for 10\n",
    "    # epochs with full training set\n",
    "    \n",
    "    myCNN.add(Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),activation='relu', \n",
    "                     padding='valid',kernel_initializer='random_uniform',name='Conv1',\n",
    "                     input_shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3])))\n",
    "    myCNN.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    myCNN.add(Conv2D(filters=64,kernel_size=(5,5),strides=(1,1),activation='relu',name='Conv2',\n",
    "                     padding='valid',kernel_initializer='random_uniform'))\n",
    "    myCNN.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    myCNN.add(Flatten())\n",
    "    myCNN.add(Dense(100,activation='relu',kernel_initializer='random_uniform'))\n",
    "    myCNN.add(Dense(10,activation='sigmoid',kernel_initializer='random_uniform'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
